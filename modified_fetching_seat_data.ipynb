{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26-Jun-2024'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only manual input given to file\n",
    "#note that 1st letter is always upper case and rest of all are lowercase letters\n",
    "src_name = \"Hyderabad\"\n",
    "dst_name = \"Tirupati\"\n",
    "#delay_days=1\n",
    "next_day = \"26-Jun-2024\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import shlex\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# List of cities with their IDs\n",
    "cities = {\n",
    "    \"Mumbai\": 462,\n",
    "    \"Hyderabad\": 124,\n",
    "    \"Bangalore\": 122,\n",
    "    \"Chennai\": 123,\n",
    "    \"Vizag\": 248,\n",
    "    \"Vijayawada\": 134,\n",
    "    \"Guntur\": 137,\n",
    "    \"Tirupati\": 71756,\n",
    "    \"Madurai\": 126,\n",
    "    \"Coimbatore\": 141,\n",
    "    \"Trichy\": 71929,\n",
    "    \"Pondicherry\": 233,\n",
    "    \"Pune\": 130,\n",
    "    \"Indore\": 313,\n",
    "    \"Nagpur\": 624,\n",
    "    \"Goa\": 210,\n",
    "    \"Warangal\": 95479,\n",
    "    \"Nellore\": 131,\n",
    "    \"Kochi\": 216,\n",
    "    \"Dharwad\": 167,\n",
    "    \"Mysore\": 129,\n",
    "    \"Mangaluru\": 95222,\n",
    "    \"Thiruvananthapuram\": 71425\n",
    "}\n",
    "#date_of_extraction = (datetime.datetime.now() + datetime.timedelta(days=delay_days))\n",
    "#next_day = (datetime.datetime.now() + datetime.timedelta(days=delay_days)).strftime('%d-%b-%Y')\n",
    "main_filepath=fr\"C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\{src_name}_to_{dst_name}\\data_on_{next_day}\"\n",
    "os.makedirs(main_filepath,exist_ok=True)\n",
    "next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved buses_on_26-Jun-2024_at_05PM,24-06-2024.csv\n"
     ]
    }
   ],
   "source": [
    "#1 getting different buses in a route\n",
    "src_id = cities[src_name]\n",
    "dst_id = cities[dst_name]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_data(from_city_id, to_city_id, src_name, dst_name, max_retries=10, retry_delay=5):\n",
    "    #next_day = (datetime.datetime.now() + datetime.timedelta(days=1)).strftime('%d-%b-%Y')\n",
    "    url = f'https://www.redbus.in/search/SearchV4Results?fromCity={from_city_id}&toCity={to_city_id}&DOJ={next_day}&sectionId=0&groupId=0&limit=0&offset=0&sort=0&sortOrder=0&meta=true&returnSearch=0'\n",
    "    headers = {\n",
    "        'accept': 'application/json, text/plain, */*',\n",
    "        'accept-language': 'en-US,en;q=0.9',\n",
    "        'content-type': 'application/json',\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        response = requests.post(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"404 Not Found: The requested resource for {src_name} to {dst_name} does not exist.\")\n",
    "            return None  # Exit if resource not found\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1}: Access Denied with error code: {response.status_code}\")\n",
    "            time.sleep(retry_delay)  # Wait before the next retry\n",
    "\n",
    "    print(f\"Failed to retrieve data after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "#data = fetch_data(src_id, dst_id, src_name, dst_name)\n",
    "#data\n",
    "\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "data = fetch_data(src_id, dst_id, src_name, dst_name)\n",
    "if data:\n",
    "        buses_info = [\n",
    "            {\n",
    "                    \"travelsName\": inv['travelsName'],\n",
    "                    \"totalRatings\": inv['totalRatings'],\n",
    "                    \"TotaReviews\":inv['numberOfReviews'],\n",
    "                    \"departureTime\": inv['departureTime'],\n",
    "                    \"arrivalTime\": inv['arrivalTime'],\n",
    "                    \"operatorId\": inv['operatorId'],\n",
    "                    \"routeId\": inv['routeId'],\n",
    "                    \"BusType\": inv['busType'],\n",
    "                    \"AC\": \"YES\" if inv.get('isAc', False) else \"NO\",\n",
    "                    \"Seater\": \"YES\" if inv.get('isSeater', False) else \"NO\",\n",
    "                    \"Sleeper\": \"YES\" if inv.get('isSleeper', False) else \"NO\",\n",
    "            }\n",
    "                for inv in data.get('inventories', [])\n",
    "            ]\n",
    "            \n",
    "df = pd.DataFrame(buses_info)\n",
    "# Add extra rows for summaries\n",
    "total_buses = len(df)\n",
    "highly_rated_buses = sum(df['totalRatings'] >= 4)\n",
    "summary_rows = pd.DataFrame({\n",
    "                \"travelsName\": [\"Total Buses\", \"Buses Rated >= 4\"],\n",
    "                \"totalRatings\": [total_buses, highly_rated_buses],\n",
    "                \"departureTime\": [\"\", \"\"],\n",
    "                \"arrivalTime\": [\"\", \"\"],\n",
    "                \"operatorId\": [\"\", \"\"],\n",
    "                \"routeId\": [\"\", \"\"],\n",
    "                \"BusType\": [\"\", \"\"],\n",
    "                \"AC\": [\"\", \"\"],\n",
    "                \"Seater\": [\"\", \"\"],\n",
    "                \"Sleeper\": [\"\", \"\"]\n",
    "            })\n",
    "df = pd.concat([df, summary_rows], ignore_index=True)\n",
    "now=datetime.datetime.now()\n",
    "now = now.strftime(\"%I%p,%d-%m-%Y\")            \n",
    "filename = f\"buses_on_{next_day}_at_{now}.csv\"\n",
    "filepath  = os.path.join(main_filepath,filename)\n",
    "df.to_csv(filepath, index=False)\n",
    "print(f\"Saved {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\IntrCity SmartBus_20437_26090661\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Ramana Tours And Travels_9138_29059495\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Zingbus Plus_20218_21603655\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Yolo Bus_20259_29542661\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\IntrCity SmartBus_20437_15995270\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Jagan Travels_16410_21078233\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Moksha Travels_28031_27203862\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Srivastav Travels_29535_29217245\\24-06-2024,17-22.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\CGR  Travels_4779_16989723\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Jagan Travels_16410_19109627\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Sai Karthik Travels_24262_21601885\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Jagan Travels_16410_29812153\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\CMR Express_23873_20960674\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\ANAGHA TRAVELS_26880_25731868\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\SRI KARTHIK TRAVELS_25485_23340631\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\CMR Express_23873_20960675\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\CGR  Travels_4779_8137178\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Vikram Travels_19085_14501581\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Vandana Travels_18164_27925268\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\PMR Express_29961_29905375\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Sri Krishna Travels_19759_21811067\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Vandana Travels_18164_17160413\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Mozo travels_16067_27543127\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Balaji Cabs_29666_29064254\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Mozo travels_16067_27542961\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Moksha Travels_28031_30654946\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\ANAGHA TRAVELS_26880_27544922\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\ANAGHA TRAVELS_26880_30102282\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\V Kaveri Travels_16797_19441865\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Go Tour Travels and Holidays_25286_29921294\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Jagan Travels_16410_28048518\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Orange Tours And Travels_18112_20941934\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Jagan Travels_16410_29941673\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Orange Tours And Travels_18112_20714653\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\V Kaveri Travels_16797_24500140\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Meghana Travels_29094_28151464\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\SREE LEKYAA TRAVELS_28114_29935280\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Orange Tours And Travels_18112_22347858\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Orange Tours And Travels_18112_18429058\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Orange Tours And Travels_18112_21821832\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\KKaveri Travels_19504_26367016\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Sri Krishna Travels_19759_14422614\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Morning Star Travels_20397_16670809\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Morning Star Travels_20397_18005032\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Morning Star Travels_20397_25915927\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Sri Krishna Travels_19759_17404898\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Tranzindia Travels_25245_24103819\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\PMR Express_29961_30835020\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\True Bus_23414_20458244\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Tranzindia Travels_25245_24136792\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\VEGA BUS_27202_28587334\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Hriday Tours & Travels_29725_30765193\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\Vandana Travels_18164_30382961\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\True Bus_23414_30418935\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\GOWTHAMI TOURS AND TRAVELS_26419_26370628\\24-06-2024,17-23.csv'.\n",
      "Data extraction complete and saved to 'C:\\Users\\T VIJAYA BALAJI\\Desktop\\final_data_collection\\Hyderabad_to_Tirupati\\data_on_26-Jun-2024\\buses_on_26-Jun-2024\\PMR Express_29961_31326419\\24-06-2024,17-23.csv'.\n",
      "sucesfully fetched data :)\n"
     ]
    }
   ],
   "source": [
    "#2 saving seat data of each bus in diffrent directories\n",
    "#input for cell : csv file contining different buses\n",
    "now=datetime.datetime.now()\n",
    "now = now.strftime(\"%I%p,%d-%m-%Y\")           \n",
    "filename = f\"buses_on_{next_day}_at_{now}.csv\"\n",
    "buses_csv_file_path  = os.path.join(main_filepath,filename)\n",
    "\n",
    "dummyfilename=f\"buses_on_{next_day}\"\n",
    "output_dir=os.path.join(main_filepath,dummyfilename)\n",
    "\n",
    "\n",
    "#step-1:first setting our curl command\n",
    "#this function takes tok, fromCityId, toCityId,operator_id,route_id as input and returns curl command important thing for using this function is giving token input argumrnt for the function as it is not taken from any exterior csv files by default im giving token as some value\n",
    "def generate_curl_command(tok, fromCityId, toCityId,operator_id,route_id):\n",
    "    # Calculate the next day's date\n",
    "    #next_day = (datetime.datetime.now() + datetime.timedelta(days=delay_days)).strftime('%d-%b-%Y')    \n",
    "    # Base cURL command template\n",
    "    curl_command_template = '''\n",
    "    curl 'https://www.redbus.in/search/seatlayout/{route_id}/{date}/{operator_id}?isRedDealApplicable=false&tok={tok}&srcCountry=IND&InvPos=1' \\\n",
    "      -H 'accept: application/json, text/plain, */*' \\\n",
    "      -H 'accept-language: en-US,en;q=0.9' \\\n",
    "      -H 'cookie: jfpj=386e43f4851d3c7d15936f880c19eeb7; _gcl_au=1.1.1651692991.1715575898; tvc_smc_bus=google / organic / (not set); mriClientId=WD5c509415-c921-4880-ab5b-ad9a968ccd55; gClId=1195023281.1715575899; rtcInline=V2; dynamic_custinfo=V1; srcCountry=IND; destCountry=IND; _fbp=fb.1.1715575924793.1120299924; srpUserTypeVal=GUEST; singleSeatCoachMark=2; rbuuid=512ed1b0-110b-11ef-98bc-155d27275705; userSessionId=ID_hd5t56d1l; rb_fpData=%7B%22browserName%22%3A%22Chrome%22%2C%22browserVersion%22%3A%22125.0.0.0%22%2C%22os%22%3A%22Windows%22%2C%22osVersion%22%3A%2210%22%2C%22screenSize%22%3A%221536%2C816%22%2C%22screenDPI%22%3A1.25%2C%22screenResolution%22%3A%221920x1080%22%2C%22screenColorDepth%22%3A24%2C%22aspectRatio%22%3A%2216%3A9%22%2C%22systemLanguage%22%3A%22en-US%22%2C%22connection%22%3A%224g%22%2C%22userAgent%22%3A%22mozilla/5.0%20%28windows%20nt%2010.0%3B%20win64%3B%20x64%29%20applewebkit/537.36%20%28khtml%2C%20like%20gecko%29%20chrome/125.0.0.0%20safari/537.36%7CWin32%7Cen-US%22%2C%22timeZone%22%3A5.5%7D; PrimoDetails=%7B%22lastUpdated%22%3A%222024-05-13%22%2C%22lastShown%22%3A%222024-05-21%22%7D; country=IND; currency=INR; defaultlanguage=en; language=en; selectedCurrency=INR; abExps=[\"rtcInline\",\"dynamic_custinfo\"]; abExpsVariants=rtcInline:V2?dynamic_custinfo:V1; tvc_session_alive_bus=1; _gid=GA1.2.319393201.1716373399; _gat_UA-9782412-15=1; _dc_gtm_UA-9782412-15=1; reqOrigin=IND; mriClientIdSetDate=5%2F22%2F24%2010%3A23%3A18%20AM; bCore=1; defaultCountry=IND; deviceSessionId=9ac6deb2-0de7-4b20-bfe8-89d368afde55; mriSessionId=WD64475fb4-f557-48b7-83d0-b25b93f53db5; lzFlag=0; ak_bmsc=E38D836E2B2730F2D6C6BB99391EECB8~000000000000000000000000000000~YAAQlbcsMYJyj22PAQAAAabTnxfj82vLRKhm0rVw1tPN/7C3V/fgXrHT2TEfWe9Xmap3gCy5u9YXAKkeTtkEfYtTMHjo5Ao4sDeu+N++Z1ii1hnkQq72j7R4msCw+Qzg7Lgn2l96lJfJY2KGOYo7u2Ov3AH6ZH//Aa5LcAvPv8jp7xbyGAI8DF1RxZmXVB8gYphPoYSZBr6jLI9YwxUQ+zRlqRXARNDe/POGEYmgxfJbIEjcfNKiAQF+lj93t7oenXuzbfbAWSvgAvhi7Z4vEWRa0+RdunkyFaz24f6QqnkNMqmFXcWbmvwjOUaTpL9HV+J53ol8Sg4/t6lV6vs4AxKTtQXuU/xjfeJCoXDE7jIXm2ShwliyKNXJtv/HR+L9NIA4Uq3snlY/DMiQsbhNd4qCk09A7aRN5gbjLNTaMMMEc5pSPenXpB0pN/CG96X8TsLa5b6ubrR0mCs0; moe_uuid=753cb754-3e23-4350-bf29-e4520bf8dd35; isBrowserFP=true; Branch_BrowserFingerPrintID=1216998847458037070; CountryName=INDIA; _ga=GA1.2.1195023281.1715575899; searchId=9cbe2c87741b4254b9532dde86b82a97; bm_sv=089DFD73A6BC507E91CD2DF0A0D29533~YAAQlbcsMed3j22PAQAAiu7TnxcLdq7ZwUnGxk0PRHY1UutQCg23eTGz4vxaVNUgHXppoUHEc+LpI6VnNWdkqfey4cApMWHVtug7cJxna1ssGdvomMTQgvfg00k3VIGGY4oegTbFN3uSvncE5Zdoxm6/NTGY3sCoAXkzOXcDI3zEaag9y4R7eukZGQnoJktqNUP2LoOTfBeUg5DDzX6W6WNhKEGnT4FxuXuGRDI2ASHNbbrdaK+OfCzJE6t7+csr~1; resumeBook=true; _ga_3NXW5V9V8S=GS1.2.1716373399.28.1.1716373424.35.0.0; _VTok={tok}; _ga_1SE754V89Y=GS1.1.1716373398.36.1.1716373424.34.0.117391036' \\\n",
    "      -H 'referer: https://www.redbus.in/search?fromCityId={fromCityId}&srcCountry=IND&toCityId={toCityId}&destCountry=IND&onward={date}&opId=0&busType=Any' \\\n",
    "      -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36' \\\n",
    " '''\n",
    "    # Format the cURL command with the provided arguments\n",
    "    curl_command = curl_command_template.format(tok=tok, fromCityId=fromCityId, toCityId=toCityId, date=next_day,operator_id=operator_id,route_id=route_id)    \n",
    "    return curl_command\n",
    "\n",
    "#step-2:changing my curl request to response.json\n",
    "#this function takes curl command as input and returns data of json file we can take json data of particualr curl\n",
    "def curl_to_response_json(curl_command):\n",
    "    tokens = shlex.split(curl_command)\n",
    "    headers, data, url = {}, None, None\n",
    "    it = iter(tokens)\n",
    "    for token in it:\n",
    "        if token == 'curl': continue\n",
    "        elif token.startswith('http'): url = token\n",
    "        elif token in ['-X', '--request']: method = next(it).upper()\n",
    "        elif token in ['-H', '--header']: header = next(it); key, value = header.split(':', 1); headers[key.strip()] = value.strip()\n",
    "        elif token in ['-d', '--data', '--data-raw', '--data-binary']: data = next(it)\n",
    "    if headers.get('Content-Type') == 'application/json' and data: data = json.loads(data)\n",
    "    for attempt in range(5):\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        if response.status_code == 200: return response.json()\n",
    "        elif response.status_code == 404: print(\"404 Not Found.\"); return None\n",
    "        else: print(f\"Attempt {attempt+1}: Error {response.status_code}\"); time.sleep(2)\n",
    "    print(\"Failed to retrieve data after 5 attempts.\"); return None\n",
    "\n",
    "#step-3:saving my json file to my required format csv file\n",
    "#takes data as input which is assumed to be a json file and saving the output csv file  \n",
    "def response_json_to_required_csv_format(data,directory_for_saving_seat_data_of_particular_route,operator_id,route_id):\n",
    "    # Navigate to the 'seatlist' which contains the relevant data\n",
    "    seatlist = data.get('seatlist', [])\n",
    "\n",
    "    # Prepare a list to hold the data\n",
    "    extracted_data = []\n",
    "\n",
    "    # Extract data from each seat\n",
    "    for seat in seatlist:\n",
    "        fares_amount = seat.get('fares', {}).get('amount', None)\n",
    "        id = seat.get('Id', None)\n",
    "        is_available = seat.get('IsAvailable', None)\n",
    "        \n",
    "        # Append the extracted data as a tuple to the list\n",
    "        extracted_data.append((id, fares_amount, is_available))\n",
    "\n",
    "    # Convert the list of tuples into a DataFrame\n",
    "    df = pd.DataFrame(extracted_data, columns=['seat', 'Fares_Amount', 'Is_Available'])\n",
    "    df['occupied'] = df['Is_Available'].apply(lambda x: 0 if x else 1)\n",
    "    df['revenue'] = df['Fares_Amount'] * df['occupied']\n",
    "\n",
    "    travels_name = data.get('Travels', 'Unknown_Travel')\n",
    "    fromcity=data.get('FromCity','Unkown_city')\n",
    "    tocity=data.get('ToCity','Unkown_city')\n",
    "    \n",
    "\n",
    "    # Add a final row with the total revenue\n",
    "    final_row = pd.DataFrame({\n",
    "        'seat': ['Travels Name','journey route','operator_id','route_id'],\n",
    "        'Fares_Amount': ['','','',''],\n",
    "        'Is_Available': ['','','',''],\n",
    "        'occupied': ['','','',''],\n",
    "        'revenue': [f'{travels_name}',f'{fromcity}-{tocity}',operator_id,route_id]\n",
    "    })\n",
    "\n",
    "    # Append the row to the DataFrame\n",
    "    df = pd.concat([df, final_row], ignore_index=True)\n",
    "\n",
    "    # Get the current date and time\n",
    "#    current_datetime = datetime.datetime.now()\n",
    "\n",
    "    # Format the current date and time\n",
    " #   formatted_datetime = current_datetime.strftime(\"%I.%M%p,%d-%m-%Y\")\n",
    "    \n",
    "    now=datetime.datetime.now()    \n",
    "    now = now.strftime(\"%d-%m-%Y,%H-%M\") \n",
    "    file_name_format = f\"{now}.csv\"\n",
    "    #filename changed for convinece here\n",
    "    #from     file_name_format = f\"{travels_name}_{operator_id}_{route_id}_seat_data_on_{formatted_datetime}_at_{now}.csv\"\n",
    "    #to     file_name_format = f\"seat_data_on_{formatted_datetime}_at_{now}.csv\"\n",
    "\n",
    "\n",
    "    os.makedirs(directory_for_saving_seat_data_of_particular_route, exist_ok=True)\n",
    "\n",
    "    # Generate the file name\n",
    "    file_name = os.path.join(directory_for_saving_seat_data_of_particular_route,file_name_format )\n",
    "\n",
    "    try:\n",
    "       df.to_csv(file_name, index=False)\n",
    "       print(f\"Data extraction complete and saved to '{file_name}'.\")\n",
    "    except Exception as e:\n",
    "       print(f\"Failed to save data to '{file_name}': {e}\")   \n",
    "\n",
    "\n",
    "def process_single_route(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[:-2]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        tok = 62480135398\n",
    "        operator_id = int(row['operatorId'])\n",
    "       # print(operator_id)\n",
    "        route_id = int(row['routeId'])\n",
    "       # print(route_id)\n",
    "        fromCityId = cities[src_name]\n",
    "       # print(fromCityId)\n",
    "        toCityId = cities[dst_name]        \n",
    "       # print(toCityId)\n",
    "        output_directory = os.path.join(output_dir, f\"{row['travelsName']}_{operator_id}_{route_id}\")\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        if not np.isnan(fromCityId) and not np.isnan(toCityId):\n",
    "          curl_command = generate_curl_command(tok, fromCityId, toCityId, operator_id, route_id)\n",
    "          data = curl_to_response_json(curl_command)\n",
    "          if data:\n",
    "            response_json_to_required_csv_format(data, output_directory,operator_id,route_id)\n",
    "          else:\n",
    "            print(f\"Failed to retrieve data for row index {index}\")\n",
    "\n",
    "process_single_route(buses_csv_file_path)\n",
    "print(\"sucesfully fetched data :)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
